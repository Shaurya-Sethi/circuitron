The mcp server provides an optional knowledge graph system that indexes code from GitHub repositories in Neo4j. When the USE_KNOWLEDGE_GRAPH option is enabled, two MCP tools become available:

check_ai_script_hallucinations – validates AI‑generated Python scripts

query_knowledge_graph – interactive querying of the Neo4j graph

How hallucination checks work
The check_ai_script_hallucinations tool is declared in src/crawl4ai_mcp.py.
Its docstring explains that it analyzes a script by validating imports, method calls, class instantiations, function calls, and attribute accesses against the Neo4j knowledge graph:

async def check_ai_script_hallucinations(ctx: Context, script_path: str) -> str:
    """
    Check an AI-generated Python script for hallucinations using the knowledge graph.

    This tool analyzes a Python script for potential AI hallucinations by validating
    imports, method calls, class instantiations, and function calls against a Neo4j
    knowledge graph containing real repository data.
    ...
    Returns:
        JSON string with hallucination detection results, confidence scores, and recommendations
    """

The function then:

Verifies that the knowledge graph is enabled and available.

Validates the provided script path.

Uses AIScriptAnalyzer (AST-based) to extract imports, class instantiations, method calls, function calls, and attribute accesses.

Passes the analysis to KnowledgeGraphValidator.validate_script, which cross‑checks these elements with the graph.

Generates a detailed report via HallucinationReporter.generate_comprehensive_report.

Returns a JSON response summarizing overall confidence, counts of valid/invalid/not‑found items, detected hallucinations, recommendations, and library statistics.

The result structure is shown in the code:

return json.dumps({
    "success": True,
    "script_path": script_path,
    "overall_confidence": validation_result.overall_confidence,
    "validation_summary": {
        "total_validations": report["validation_summary"]["total_validations"],
        "valid_count": report["validation_summary"]["valid_count"],
        "invalid_count": report["validation_summary"]["invalid_count"],
        "uncertain_count": report["validation_summary"]["uncertain_count"],
        "not_found_count": report["validation_summary"]["not_found_count"],
        "hallucination_rate": report["validation_summary"]["hallucination_rate"]
    },
    "hallucinations_detected": report["hallucinations_detected"],
    "recommendations": report["recommendations"],
    "analysis_metadata": {
        "total_imports": report["analysis_metadata"]["total_imports"],
        "total_classes": report["analysis_metadata"]["total_classes"],
        "total_methods": report["analysis_metadata"]["total_methods"],
        "total_attributes": report["analysis_metadata"]["total_attributes"],
        "total_functions": report["analysis_metadata"]["total_functions"]
    },
    "libraries_analyzed": report.get("libraries_analyzed", [])
}, indent=2)

Underlying validation logic
knowledge_graphs/knowledge_graph_validator.py drives the checks. It defines dataclasses for validation results and implements the validator:

class KnowledgeGraphValidator:
    """Validates code against Neo4j knowledge graph"""

    async def validate_script(self, analysis_result: AnalysisResult) -> ScriptValidationResult:
        result = ScriptValidationResult(
            script_path=analysis_result.file_path,
            analysis_result=analysis_result
        )

        result.import_validations = await self._validate_imports(analysis_result.imports)
        result.class_validations = await self._validate_class_instantiations(
            analysis_result.class_instantiations
        )
        result.method_validations = await self._validate_method_calls(
            analysis_result.method_calls
        )
        result.attribute_validations = await self._validate_attribute_accesses(
            analysis_result.attribute_accesses
        )
        result.function_validations = await self._validate_function_calls(
            analysis_result.function_calls
        )
        result.overall_confidence = self._calculate_overall_confidence(result)
        result.hallucinations_detected = self._detect_hallucinations(result)
        return result

Each _validate_* method checks whether the element exists in the graph and whether parameter usage matches the stored signatures. When something is missing or parameters are incorrect, the validator records a NOT_FOUND or INVALID result with suggestions.

Reporting the results
HallucinationReporter assembles a structured report with both JSON and Markdown output. It categorizes every validation item and provides recommendations:

report = {
    'analysis_metadata': {...},
    'validation_summary': {...},
    'libraries_analyzed': library_summary,
    'validation_details': {
        'valid_items': valid_items,
        'invalid_items': invalid_items,
        'uncertain_items': uncertain_items,
        'not_found_items': not_found_items
    },
    'hallucinations_detected': validation_result.hallucinations_detected,
    'recommendations': self._generate_recommendations(validation_result)
}

The reporter can also generate a Markdown document and print a console summary showing the number of hallucinations and recommendations for fixing them. Those recommendations point out missing methods, wrong parameters, or missing attributes, helping you correct the script.

Using the tool
The README describes enabling the knowledge graph and running the hallucination detector:

1. **Add a repository**

   > “Add `https://github.com/pydantic/pydantic-ai.git` to the knowledge graph”
   (The URL must end in `.git`.)

2. **Check a script for hallucinations**

   ```bash
   python knowledge_graphs/ai_hallucination_detector.py /path/to/your_script.py
These commands are also available to AI coding assistants through the parse_github_repository and check_ai_script_hallucinations tools.

​:codex-file-citation[codex-file-citation]{line_range_start=272 line_range_end=284 path=README.md git_url="https://github.com/Shaurya-Sethi/mcp-crawl4ai-rag/blob/configurable-throttle/README.md#L272-L284"}​

With `USE_KNOWLEDGE_GRAPH=true` and a Neo4j database running, you can call the `check_ai_script_hallucinations` tool (either via the CLI above or via MCP) to validate any Python file.

### `query_knowledge_graph` tool

Another MCP tool, `query_knowledge_graph`, offers interactive access to the Neo4j database. Its docstring lists available commands and the schema of the graph:

async def query_knowledge_graph(ctx: Context, command: str) -> str:
"""
Query and explore the Neo4j knowledge graph containing repository data.

This tool provides comprehensive access to the knowledge graph for exploring repositories,
classes, methods, functions, and their relationships. Perfect for understanding what data
is available for hallucination detection and debugging validation results.

**⚠️ IMPORTANT: Always start with the `repos` command first!**
Before using any other commands, run `repos` to see what repositories are available
in your knowledge graph. ...

## Available Commands:
**Repository Commands:**
- `repos` - **START HERE!** List all repositories in the knowledge graph
- `explore <repo_name>` - Get detailed overview of a specific repository
**Class Commands:**
- `classes` - List all classes across all repositories (limited to 20)
- `classes <repo_name>` - List classes in a specific repository
- `class <class_name>` - Get detailed information about a specific class including methods and attributes
**Method Commands:**
- `method <method_name>` - Search for methods by name across all classes
- `method <method_name> <class_name>` - Search for a method within a specific class
**Custom Query:**
- `query <cypher_query>` - Execute a custom Cypher query (results limited to 20 records)
"""
​:codex-file-citation[codex-file-citation]{line_range_start=1170 line_range_end=1227 path=src/crawl4ai_mcp.py git_url="https://github.com/Shaurya-Sethi/mcp-crawl4ai-rag/blob/configurable-throttle/src/crawl4ai_mcp.py#L1170-L1227"}​

This tool can list repositories, show class or method details, or run custom Cypher queries. It helps explore what code elements are available and is useful when interpreting hallucination reports.

### Summary

In short:

- `check_ai_script_hallucinations` analyzes a Python script with AST, validates all code elements against a Neo4j knowledge graph of real repositories, and outputs a detailed JSON report containing detected hallucinations and recommendations for fixes.
- Results include counts of valid/invalid items, line numbers of hallucinations, and suggestions for corrections.
- `query_knowledge_graph` lets you explore the indexed repositories with commands such as `repos`, `classes`, and `method`, making it easier to understand the graph data or verify issues found during hallucination checks. The README lists these tools as part of the knowledge graph feature set (requiring `USE_KNOWLEDGE_GRAPH=true`)​:codex-file-citation[codex-file-citation]{line_range_start=55 line_range_end=71 path=README.md git_url="https://github.com/Shaurya-Sethi/mcp-crawl4ai-rag/blob/configurable-throttle/README.md#L55-L71"}​.

