Notes

The SSE server sends an "endpoint" event, not a "session" event, when the stream opens.

Direct HTTP JSON-RPC calls are not implemented—use SSE (TRANSPORT=sse) or stdio (TRANSPORT=stdio).

Developer’s Guide to Using Fast‑MCP for RAG
1. Repository Structure & Installation
.
├── Dockerfile
├── LICENSE
├── README.md
├── crawled_pages.sql
├── knowledge_graphs/
│   ├── ai_hallucination_detector.py
│   ├── ai_script_analyzer.py
│   ├── hallucination_reporter.py
│   ├── knowledge_graph_validator.py
│   ├── parse_repo_into_neo4j.py
│   ├── query_knowledge_graph.py
│   └── test_script.py
├── pyproject.toml
├── src/
│   ├── crawl4ai_mcp.py
│   └── utils.py
└── uv.lock
Key files:

src/crawl4ai_mcp.py – FastMCP server with all tool registrations.

src/utils.py – Supabase helpers, OpenAI embedding utilities and RAG support.

crawled_pages.sql – Supabase schema for documents and code examples.

Installation

Clone the repo.

Install Python dependencies:

pip install .
(pyproject.toml lists dependencies such as crawl4ai, mcp, openai, supabase.)

Or build the Docker image:

docker build -t mcp/crawl4ai-rag .
The Dockerfile installs the package and runs crawl4ai-setup.

2. Server Startup & Configuration
The server entry point is src/crawl4ai_mcp.py.
It loads variables from .env and uses them when creating FastMCP:

mcp = FastMCP(
    "mcp-crawl4ai-rag",
    description="MCP server for RAG and web crawling with Crawl4AI",
    lifespan=crawl4ai_lifespan,
    host=os.getenv("HOST", "0.0.0.0"),
    port=os.getenv("PORT", "8051")
)

Running
Python: uv run src/crawl4ai_mcp.py

Docker: docker run --env-file .env -p 8051:8051 mcp/crawl4ai-rag

Environment Variables
Excerpt from .env sample:

HOST=0.0.0.0
PORT=8051
TRANSPORT=sse
OPENAI_API_KEY=your_openai_api_key
MODEL_CHOICE=gpt-4.1-nano
LLM_MAX_CONCURRENCY=3
LLM_REQUEST_DELAY=0
USE_CONTEXTUAL_EMBEDDINGS=false
USE_HYBRID_SEARCH=false
USE_AGENTIC_RAG=false
USE_RERANKING=false
USE_KNOWLEDGE_GRAPH=false
SUPABASE_URL=your_supabase_project_url
SUPABASE_SERVICE_KEY=your_supabase_service_key
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password

TRANSPORT determines whether main() calls mcp.run_sse_async() or mcp.run_stdio_async():

async def main():
    transport = os.getenv("TRANSPORT", "sse")
    if transport == 'sse':
        await mcp.run_sse_async()
    else:
        await mcp.run_stdio_async()

Other variables configure RAG strategies (USE_*), OpenAI limits (LLM_MAX_CONCURRENCY, LLM_REQUEST_DELAY), and external services (Supabase, Neo4j).

3. Transport Modes & HTTP/SSE Endpoints
stdio
With TRANSPORT=stdio, the server communicates over standard input/output and no HTTP endpoints are used.

SSE (HTTP-based)
With TRANSPORT=sse (default), FastMCP creates a Starlette app with routes:

GET /sse – establishes an SSE connection.

POST /messages/?session_id=... – JSON-RPC message endpoint.

Default paths come from FastMCP settings (sse_path='/sse', message_path='/messages/').

Session negotiation
/sse responds with an initial SSE event:

event: endpoint
data: /messages/?session_id=<uuid>

The client must POST JSON-RPC messages to that endpoint URL. A valid request returns HTTP 202. Errors include:

400 if session_id is missing or invalid.

404 if the session ID is unknown.

Responses stream back over the same SSE connection as event: message.

HTTP mode
There is no separate HTTP JSON-RPC endpoint. All network access uses the SSE pair above.

4. Tool Registration & RAG API
Each tool is decorated with @mcp.tool() in src/crawl4ai_mcp.py. The function name is the JSON‑RPC method name.

JSON‑RPC method	Signature (summary)
crawl_single_page	(ctx, url: str) -> str – Crawl one page.
smart_crawl_url	(ctx, url: str, max_depth: int=3, max_concurrent: int=10, chunk_size: int=5000) -> str – Auto-detect page/sitemap/text crawling.
get_available_sources	(ctx) -> str – List crawled domains.
perform_rag_query	(ctx, query: str, source: str=None, match_count: int=5) -> str – Standard RAG search.
search_code_examples	(ctx, query: str, source_id: str=None, match_count: int=5) -> str – Search stored code snippets.
check_ai_script_hallucinations	(ctx, script_path: str) -> str – Validate a Python script using the Neo4j knowledge graph.
query_knowledge_graph	(ctx, command: str) -> str – Query Neo4j with commands like repos, explore <repo> etc.
parse_github_repository	(ctx, repo_url: str) -> str – Clone and parse a repo into Neo4j.
These functions use helpers from src/utils.py to talk to Supabase and OpenAI.

5. Client Usage Examples
Python (using httpx and httpx_sse)
import asyncio, json, httpx
from httpx_sse import aconnect_sse

async def main():
    async with httpx.AsyncClient() as client:
        # 1. Open SSE stream
        async with aconnect_sse(client, "GET", "http://localhost:8051/sse") as es:
            async for event in es.aiter_sse():
                if event.event == "endpoint":
                    endpoint = httpx.URL("http://localhost:8051").join(event.data)
                    break

            # 2. Send JSON‑RPC request
            req = {
                "jsonrpc": "2.0",
                "id": 1,
                "method": "perform_rag_query",
                "params": {"query": "capacitor 0.1µF decoupling", "match_count": 5}
            }
            await client.post(endpoint, json=req)

            # 3. Receive streamed response
            async for event in es.aiter_sse():
                if event.event == "message":
                    resp = json.loads(event.data)
                    print(resp)
                    break

asyncio.run(main())
curl (SSE)
Connect to /sse (keep the connection open):

curl -N http://localhost:8051/sse
The first event contains data: /messages/?session_id=<id>.

Post a JSON‑RPC request:

curl -X POST \
     -H "Content-Type: application/json" \
     -d '{"jsonrpc":"2.0","id":1,"method":"perform_rag_query","params":{"query":"capacitor 0.1µF decoupling","match_count":5}}' \
     "http://localhost:8051/messages/?session_id=<id>"
Responses arrive as SSE message events.

stdio
When TRANSPORT=stdio, run the server and communicate via stdin/stdout using the MCP client of your choice.

6. Error Handling & Troubleshooting
400 Bad Request – Missing or invalid session_id, or invalid JSON in POST body.

404 Not Found – POSTed session ID does not exist.

405 Method Not Allowed – Using an unsupported HTTP verb on /sse or /messages/.

Connection issues – ensure PORT and HOST are correct and that any reverse proxy forwards SSE traffic.

Enable detailed logging by setting FASTMCP_LOG_LEVEL=DEBUG (FastMCP’s environment prefix) or run the server with LOG_LEVEL=DEBUG if using uvicorn.

Client-side, log HTTP requests/responses (e.g., set httpx log level to DEBUG) to trace SSE events.

7. Best Practices & Recommendations
Transport choice

Use stdio for local agents or when integrating with tools that can spawn the process directly.

Use SSE for networked clients or containerized deployments where HTTP is convenient.

Performance

Tune LLM_MAX_CONCURRENCY and LLM_REQUEST_DELAY to respect API rate limits.

For high‑volume search, enable USE_RERANKING only when better ranking outweighs the added latency (~100–200 ms).

Streaming vs Batch

Crawling large sites can be memory‑intensive. Adjust max_concurrent in smart_crawl_url to balance speed vs resource usage.

Deployment

The server listens on HOST/PORT; behind a reverse proxy (Nginx, Traefik, Kubernetes ingress), ensure the SSE endpoint /sse supports HTTP streaming and that /messages/ is reachable.

Persist .env and the Supabase/Neo4j credentials securely (e.g., Kubernetes secrets).

By following this guide, you can integrate Fast‑MCP’s crawling and RAG capabilities into your own agent, invoke tools such as perform_rag_query through SSE or stdio, and extend the server with additional functionality as needed.